#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os

def merge_complete_sections():
    """ì™„ì „ ì²˜ë¦¬ëœ section2ì™€ section3 ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°"""
    
    # ë°ì´í„° ë¡œë“œ
    section2_path = "public/data/section2_complete_1701_2634.json"
    section3_path = "public/data/section3_complete_2635_3568.json"
    
    print("ğŸ“Š ì™„ì „ ì²˜ë¦¬ëœ íˆ¬í‘œì†Œ ë°ì´í„° í†µí•© ì‹œì‘...")
    
    # Section 2 ë¡œë“œ
    with open(section2_path, 'r', encoding='utf-8') as f:
        section2_data = json.load(f)
    print(f"âœ… Section 2 ë¡œë“œ: {len(section2_data)}ê°œ íˆ¬í‘œì†Œ")
    
    # Section 3 ë¡œë“œ
    with open(section3_path, 'r', encoding='utf-8') as f:
        section3_data = json.load(f)
    print(f"âœ… Section 3 ë¡œë“œ: {len(section3_data)}ê°œ íˆ¬í‘œì†Œ")
    
    # ì „ì²´ íˆ¬í‘œì†Œ ë°ì´í„° (ê¸°ì¡´ 1-1700 + section2 + section3)
    print("\nğŸ“ ê¸°ì¡´ 1-1700 ë°ì´í„° ë¡œë“œ...")
    try:
        with open("public/data/polling_stations_partial_1700.json", 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
        print(f"âœ… ê¸°ì¡´ ë°ì´í„°: {len(existing_data)}ê°œ íˆ¬í‘œì†Œ")
    except:
        print("âŒ ê¸°ì¡´ 1700 ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ 1800 ë°ì´í„° ì‚¬ìš©")
        with open("public/data/polling_stations_partial_1800.json", 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
        print(f"âœ… ê¸°ì¡´ ë°ì´í„°: {len(existing_data)}ê°œ íˆ¬í‘œì†Œ")
    
    # ë°ì´í„° í†µí•©
    print("\nğŸ”„ ë°ì´í„° í†µí•© ì¤‘...")
    
    # ê¸°ì¡´ ë°ì´í„°ì—ì„œ 1700 ì´í›„ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    filtered_existing = [station for station in existing_data 
                        if int(station['id'].replace('station_', '')) <= 1700]
    print(f"âœ… í•„í„°ë§ëœ ê¸°ì¡´ ë°ì´í„°: {len(filtered_existing)}ê°œ")
    
    # ëª¨ë“  ë°ì´í„° í•©ì¹˜ê¸°
    complete_data = filtered_existing + section2_data + section3_data
    print(f"ğŸ‰ í†µí•© ì™„ë£Œ: {len(complete_data)}ê°œ íˆ¬í‘œì†Œ")
    
    # ë°ì´í„° ê²€ì¦
    print("\nğŸ” ë°ì´í„° ê²€ì¦...")
    ids = [station['id'] for station in complete_data]
    unique_ids = set(ids)
    
    if len(ids) != len(unique_ids):
        print(f"âš ï¸  ì¤‘ë³µ ID ë°œê²¬: {len(ids) - len(unique_ids)}ê°œ")
        duplicates = [id for id in ids if ids.count(id) > 1]
        print(f"ì¤‘ë³µ ID: {set(duplicates)}")
    else:
        print("âœ… ì¤‘ë³µ ID ì—†ìŒ")
    
    # ì¢Œí‘œ í†µê³„
    with_coords = sum(1 for station in complete_data if station.get('coordinates'))
    print(f"âœ… ì¢Œí‘œ ë³´ìœ : {with_coords}/{len(complete_data)} ({with_coords/len(complete_data)*100:.1f}%)")
    
    # ì§€ì—­ë³„ í†µê³„
    districts = {}
    for station in complete_data:
        district = station.get('district', 'ë¯¸ë¶„ë¥˜')
        districts[district] = districts.get(district, 0) + 1
    
    print(f"\nğŸ“ ì§€ì—­ë³„ ë¶„í¬:")
    for district, count in sorted(districts.items()):
        print(f"  {district}: {count}ê°œ")
    
    # ìµœì¢… íŒŒì¼ ì €ì¥
    output_path = "public/data/polling_stations_complete_all.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(complete_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {os.path.getsize(output_path) / 1024 / 1024:.1f}MB")
    
    return len(complete_data)

if __name__ == "__main__":
    total = merge_complete_sections()
    print(f"\nğŸŠ ì „ì²´ íˆ¬í‘œì†Œ ë°ì´í„° í†µí•© ì™„ë£Œ: {total}ê°œ") 